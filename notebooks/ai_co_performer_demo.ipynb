{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Co-Performer Demo\n",
    "\n",
    "This notebook demonstrates **AI as a responsive musical partner** in BrainJam.\n",
    "\n",
    "Key concepts:\n",
    "- **Performer → AI**: Your input influences AI timing, density, and character\n",
    "- **AI → Performer**: AI responds musically (call-and-response patterns)\n",
    "- **Feedback loop**: You and AI mutually influence each other\n",
    "- **Not autonomous**: AI follows your lead, doesn't take over\n",
    "\n",
    "---\n",
    "\n",
    "## Performance Paradigm\n",
    "\n",
    "Think of the AI as a **responsive ensemble member**:\n",
    "- When you're active → AI is active\n",
    "- When you're sparse → AI fills space\n",
    "- When you're tense → AI adds tension\n",
    "- When you're calm → AI provides grounding\n",
    "\n",
    "**You maintain creative control** through your input signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio, display, clear_output\n",
    "import time\n",
    "\n",
    "# Import BrainJam performance system\n",
    "from performance_system.controllers import MockEEGController\n",
    "from performance_system.sound_engines import ParametricSynth\n",
    "from performance_system.mapping_models import LinearMapper\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize Performer and AI Systems\n",
    "\n",
    "We'll create two sound engines:\n",
    "- **Performer voice**: Directly controlled by your input\n",
    "- **AI voice**: Responds to and complements your input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize controller (performer input)\n",
    "controller = MockEEGController(fs=250)\n",
    "print(\"✓ Performer Controller initialized\")\n",
    "\n",
    "# Initialize two synthesizers\n",
    "performer_synth = ParametricSynth(sample_rate=44100, base_freq=220.0)  # A3\n",
    "ai_synth = ParametricSynth(sample_rate=44100, base_freq=329.63)  # E4 (perfect fifth)\n",
    "\n",
    "print(\"\\n✓ Performer Voice (A3 base)\")\n",
    "print(\"✓ AI Voice (E4 base - perfect fifth harmony)\")\n",
    "print(\"\\nThe AI voice will respond to and complement your input.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define AI Response Strategy\n",
    "\n",
    "The AI co-performer uses a simple but musically meaningful strategy:\n",
    "\n",
    "### Call-and-Response Pattern\n",
    "- **When performer is active (high density)** → AI is sparse (listening)\n",
    "- **When performer is sparse** → AI fills space (responding)\n",
    "\n",
    "### Harmonic Relationship\n",
    "- **When performer is consonant** → AI adds gentle harmony\n",
    "- **When performer is tense** → AI mirrors tension\n",
    "\n",
    "This creates a **musical dialogue**, not random accompaniment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AICoPerformer:\n",
    "    \"\"\"\n",
    "    AI co-performer that responds to performer input.\n",
    "    \n",
    "    Strategy:\n",
    "    - Call-and-response: Active when performer is sparse, sparse when performer is active\n",
    "    - Harmonic support: Follows performer's harmonic character\n",
    "    - Temporal memory: Remembers recent performer behavior\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, response_delay: float = 0.5):\n",
    "        \"\"\"\n",
    "        Initialize AI co-performer.\n",
    "        \n",
    "        Args:\n",
    "            response_delay: How long AI \"listens\" before responding (seconds)\n",
    "        \"\"\"\n",
    "        self.response_delay = response_delay\n",
    "        self.performer_history = []\n",
    "        self.time_since_last = 0.0\n",
    "        \n",
    "    def generate_response(self, performer_controls: dict, dt: float) -> dict:\n",
    "        \"\"\"\n",
    "        Generate AI response based on performer input.\n",
    "        \n",
    "        Args:\n",
    "            performer_controls: Current performer control vector\n",
    "            dt: Time since last call (seconds)\n",
    "            \n",
    "        Returns:\n",
    "            AI control parameters\n",
    "        \"\"\"\n",
    "        # Update history\n",
    "        self.performer_history.append(performer_controls)\n",
    "        if len(self.performer_history) > 10:  # Keep last 10 samples\n",
    "            self.performer_history.pop(0)\n",
    "        \n",
    "        self.time_since_last += dt\n",
    "        \n",
    "        # Get performer's current state\n",
    "        performer_density = performer_controls['control_1']\n",
    "        performer_tension = performer_controls['control_2']\n",
    "        performer_brightness = performer_controls['control_3']\n",
    "        \n",
    "        # Calculate average recent performer activity\n",
    "        if len(self.performer_history) > 0:\n",
    "            recent_density = np.mean([c['control_1'] for c in self.performer_history])\n",
    "        else:\n",
    "            recent_density = 0.5\n",
    "        \n",
    "        # AI STRATEGY 1: Call-and-response density\n",
    "        # Inverse relationship: sparse when performer is dense\n",
    "        ai_density = 1.0 - recent_density\n",
    "        \n",
    "        # Add some breathing room\n",
    "        ai_density = ai_density * 0.6 + 0.2  # Scale to 0.2-0.8 range\n",
    "        \n",
    "        # AI STRATEGY 2: Harmonic support\n",
    "        # Follow performer's harmonic character but slightly offset\n",
    "        ai_tension = performer_tension * 0.7  # Slightly less tense\n",
    "        \n",
    "        # AI STRATEGY 3: Complementary brightness\n",
    "        # Opposite brightness for textural contrast\n",
    "        ai_brightness = 1.0 - performer_brightness\n",
    "        \n",
    "        # AI STRATEGY 4: Gentle noise texture\n",
    "        ai_noise = 0.3  # Constant gentle texture\n",
    "        \n",
    "        return {\n",
    "            'control_1': np.clip(ai_density, 0, 1),\n",
    "            'control_2': np.clip(ai_tension, 0, 1),\n",
    "            'control_3': np.clip(ai_brightness, 0, 1),\n",
    "            'control_4': np.clip(ai_noise, 0, 1),\n",
    "        }\n",
    "\n",
    "# Initialize AI co-performer\n",
    "ai_performer = AICoPerformer(response_delay=0.5)\n",
    "print(\"✓ AI Co-Performer initialized\")\n",
    "print(\"\\nAI Strategy:\")\n",
    "print(\"  1. Call-and-response: Fills space when you're sparse\")\n",
    "print(\"  2. Harmonic support: Follows your harmonic character\")\n",
    "print(\"  3. Textural contrast: Complements your brightness\")\n",
    "print(\"  4. Gentle presence: Adds subtle texture\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate Performer + AI Duet\n",
    "\n",
    "Now let's hear the performer and AI together in a musical dialogue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset everything\n",
    "controller.reset()\n",
    "performer_synth.reset()\n",
    "ai_synth.reset()\n",
    "ai_performer = AICoPerformer()\n",
    "\n",
    "# Generate 10 seconds of duet\n",
    "duration = 10.0\n",
    "chunk_size = 0.1\n",
    "n_chunks = int(duration / chunk_size)\n",
    "\n",
    "performer_audio_chunks = []\n",
    "ai_audio_chunks = []\n",
    "performer_controls_log = []\n",
    "ai_controls_log = []\n",
    "\n",
    "print(\"Generating performer + AI duet...\")\n",
    "\n",
    "for i in range(n_chunks):\n",
    "    # Get performer control\n",
    "    performer_controls = controller.get_control_vector(duration=chunk_size)\n",
    "    performer_controls_log.append(performer_controls)\n",
    "    \n",
    "    # AI responds to performer\n",
    "    ai_controls = ai_performer.generate_response(performer_controls, chunk_size)\n",
    "    ai_controls_log.append(ai_controls)\n",
    "    \n",
    "    # Generate audio for both\n",
    "    performer_audio = performer_synth.generate(chunk_size, performer_controls)\n",
    "    ai_audio = ai_synth.generate(chunk_size, ai_controls)\n",
    "    \n",
    "    performer_audio_chunks.append(performer_audio)\n",
    "    ai_audio_chunks.append(ai_audio)\n",
    "    \n",
    "    if (i + 1) % 20 == 0:\n",
    "        print(f\"  Generated {(i + 1) * chunk_size:.1f}s / {duration}s\")\n",
    "\n",
    "# Concatenate audio\n",
    "performer_audio = np.concatenate(performer_audio_chunks)\n",
    "ai_audio = np.concatenate(ai_audio_chunks)\n",
    "\n",
    "# Mix at appropriate levels\n",
    "performer_level = 0.6\n",
    "ai_level = 0.4\n",
    "mixed_audio = performer_level * performer_audio + ai_level * ai_audio\n",
    "\n",
    "print(f\"\\n✓ Generated {duration}s of duet\")\n",
    "print(\"\\nListen to:\")\n",
    "print(\"  1. Performer voice only\")\n",
    "print(\"  2. AI voice only\")\n",
    "print(\"  3. Mixed duet\")\n",
    "\n",
    "print(\"\\n--- PERFORMER VOICE ONLY ---\")\n",
    "display(Audio(performer_audio, rate=performer_synth.sample_rate))\n",
    "\n",
    "print(\"\\n--- AI VOICE ONLY ---\")\n",
    "display(Audio(ai_audio, rate=ai_synth.sample_rate))\n",
    "\n",
    "print(\"\\n--- MIXED DUET (60% Performer + 40% AI) ---\")\n",
    "display(Audio(mixed_audio, rate=performer_synth.sample_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize the Musical Dialogue\n",
    "\n",
    "Let's see how performer and AI interact over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract control parameters\n",
    "performer_density = [c['control_1'] for c in performer_controls_log]\n",
    "performer_tension = [c['control_2'] for c in performer_controls_log]\n",
    "ai_density = [c['control_1'] for c in ai_controls_log]\n",
    "ai_tension = [c['control_2'] for c in ai_controls_log]\n",
    "\n",
    "time_axis = np.arange(len(performer_density)) * chunk_size\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "# Density (Call-and-response)\n",
    "axes[0].plot(time_axis, performer_density, 'b-', linewidth=2, label='Performer', alpha=0.8)\n",
    "axes[0].plot(time_axis, ai_density, 'r--', linewidth=2, label='AI', alpha=0.8)\n",
    "axes[0].set_ylabel('Tempo/Density', fontsize=11)\n",
    "axes[0].set_ylim([0, 1])\n",
    "axes[0].set_xlim([0, duration])\n",
    "axes[0].legend(loc='upper right', fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_title('Call-and-Response: AI is sparse when Performer is dense', \n",
    "                  fontsize=12, fontweight='bold')\n",
    "axes[0].axhline(y=0.5, color='gray', linestyle=':', alpha=0.3)\n",
    "\n",
    "# Fill areas to show inverse relationship\n",
    "axes[0].fill_between(time_axis, 0, performer_density, alpha=0.2, color='blue', label='_nolegend_')\n",
    "axes[0].fill_between(time_axis, 0, ai_density, alpha=0.2, color='red', label='_nolegend_')\n",
    "\n",
    "# Harmonic tension\n",
    "axes[1].plot(time_axis, performer_tension, 'b-', linewidth=2, label='Performer', alpha=0.8)\n",
    "axes[1].plot(time_axis, ai_tension, 'r--', linewidth=2, label='AI', alpha=0.8)\n",
    "axes[1].set_ylabel('Harmonic Tension', fontsize=11)\n",
    "axes[1].set_ylim([0, 1])\n",
    "axes[1].set_xlim([0, duration])\n",
    "axes[1].set_xlabel('Time (seconds)', fontsize=11)\n",
    "axes[1].legend(loc='upper right', fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_title('Harmonic Support: AI follows Performer with gentle support', \n",
    "                  fontsize=12, fontweight='bold')\n",
    "axes[1].axhline(y=0.5, color='gray', linestyle=':', alpha=0.3)\n",
    "\n",
    "plt.suptitle('Performer–AI Musical Dialogue', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nObserve the musical dialogue:\")\n",
    "print(\"\\n1. CALL-AND-RESPONSE (top):\")\n",
    "print(\"   - When Performer is dense (blue peaks) → AI is sparse (red valleys)\")\n",
    "print(\"   - When Performer is sparse (blue valleys) → AI fills space (red rises)\")\n",
    "print(\"\\n2. HARMONIC SUPPORT (bottom):\")\n",
    "print(\"   - AI follows Performer's harmonic character\")\n",
    "print(\"   - AI provides gentler support (lower tension)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyze Interaction Dynamics\n",
    "\n",
    "Let's quantify the performer–AI relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation between performer and AI\n",
    "density_correlation = np.corrcoef(performer_density, ai_density)[0, 1]\n",
    "tension_correlation = np.corrcoef(performer_tension, ai_tension)[0, 1]\n",
    "\n",
    "# Calculate temporal offset (AI should respond slightly delayed)\n",
    "performer_changes = np.diff(performer_density)\n",
    "ai_changes = np.diff(ai_density)\n",
    "\n",
    "# Measure responsiveness\n",
    "performer_variance = np.var(performer_density)\n",
    "ai_variance = np.var(ai_density)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"INTERACTION ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n1. Density Correlation:\")\n",
    "print(f\"   r = {density_correlation:.3f}\")\n",
    "if density_correlation < -0.3:\n",
    "    print(\"   ✓ Strong inverse relationship (call-and-response working!)\")\n",
    "elif density_correlation > 0.3:\n",
    "    print(\"   ⚠ Positive correlation (AI mimicking instead of responding)\")\n",
    "else:\n",
    "    print(\"   ~ Weak relationship (AI relatively independent)\")\n",
    "\n",
    "print(\"\\n2. Tension Correlation:\")\n",
    "print(f\"   r = {tension_correlation:.3f}\")\n",
    "if tension_correlation > 0.5:\n",
    "    print(\"   ✓ Strong positive relationship (harmonic support working!)\")\n",
    "elif tension_correlation < -0.3:\n",
    "    print(\"   ⚠ Negative correlation (AI providing contrast)\")\n",
    "else:\n",
    "    print(\"   ~ Moderate relationship\")\n",
    "\n",
    "print(\"\\n3. Activity Levels:\")\n",
    "print(f\"   Performer variance: {performer_variance:.3f}\")\n",
    "print(f\"   AI variance: {ai_variance:.3f}\")\n",
    "print(f\"   Activity ratio: {ai_variance/performer_variance:.2f}\")\n",
    "\n",
    "print(\"\\n4. Interaction Pattern:\")\n",
    "performer_mean = np.mean(performer_density)\n",
    "ai_mean = np.mean(ai_density)\n",
    "print(f\"   Performer average density: {performer_mean:.2f}\")\n",
    "print(f\"   AI average density: {ai_mean:.2f}\")\n",
    "if abs(performer_mean + ai_mean - 1.0) < 0.2:\n",
    "    print(\"   ✓ Balanced duet (complementary density levels)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"INTERPRETATION\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nThe AI is designed to be a responsive partner, not a mimic.\")\n",
    "print(\"- Negative density correlation = Call-and-response\")\n",
    "print(\"- Positive tension correlation = Harmonic support\")\n",
    "print(\"- Balanced activity = Musical dialogue, not dominance\")\n",
    "print(\"\\n✓ This creates a musical conversation, not autonomous AI.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Experiment: Different AI Response Strategies\n",
    "\n",
    "Let's try different AI behaviors to compare:\n",
    "1. **Call-and-response** (current)\n",
    "2. **Mimic** (follow performer)\n",
    "3. **Independent** (ignore performer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_duet_with_strategy(strategy='call-response', duration=5.0):\n",
    "    \"\"\"\n",
    "    Generate duet with different AI strategies.\n",
    "    \n",
    "    Args:\n",
    "        strategy: 'call-response', 'mimic', or 'independent'\n",
    "        duration: Length in seconds\n",
    "    \"\"\"\n",
    "    # Reset\n",
    "    controller.reset()\n",
    "    performer_synth.reset()\n",
    "    ai_synth.reset()\n",
    "    \n",
    "    chunk_size = 0.1\n",
    "    n_chunks = int(duration / chunk_size)\n",
    "    \n",
    "    performer_chunks = []\n",
    "    ai_chunks = []\n",
    "    \n",
    "    for i in range(n_chunks):\n",
    "        # Performer control\n",
    "        p_controls = controller.get_control_vector(duration=chunk_size)\n",
    "        \n",
    "        # AI strategy\n",
    "        if strategy == 'call-response':\n",
    "            # Inverse density, follow tension\n",
    "            ai_controls = {\n",
    "                'control_1': 1.0 - p_controls['control_1'] * 0.8 + 0.2,\n",
    "                'control_2': p_controls['control_2'] * 0.7,\n",
    "                'control_3': 1.0 - p_controls['control_3'],\n",
    "                'control_4': 0.3,\n",
    "            }\n",
    "        elif strategy == 'mimic':\n",
    "            # Follow performer exactly\n",
    "            ai_controls = p_controls.copy()\n",
    "        else:  # independent\n",
    "            # Random/independent\n",
    "            ai_controls = {\n",
    "                'control_1': 0.5,\n",
    "                'control_2': 0.5,\n",
    "                'control_3': 0.5,\n",
    "                'control_4': 0.3,\n",
    "            }\n",
    "        \n",
    "        # Generate audio\n",
    "        p_audio = performer_synth.generate(chunk_size, p_controls)\n",
    "        ai_audio = ai_synth.generate(chunk_size, ai_controls)\n",
    "        \n",
    "        performer_chunks.append(p_audio)\n",
    "        ai_chunks.append(ai_audio)\n",
    "    \n",
    "    performer_audio = np.concatenate(performer_chunks)\n",
    "    ai_audio = np.concatenate(ai_chunks)\n",
    "    mixed = 0.6 * performer_audio + 0.4 * ai_audio\n",
    "    \n",
    "    return mixed\n",
    "\n",
    "print(\"Generating duets with different AI strategies...\\n\")\n",
    "\n",
    "# Strategy 1: Call-and-response\n",
    "print(\"1. CALL-AND-RESPONSE (Musical dialogue)\")\n",
    "print(\"   AI fills space when you're sparse\")\n",
    "audio1 = generate_duet_with_strategy('call-response')\n",
    "display(Audio(audio1, rate=44100))\n",
    "\n",
    "# Strategy 2: Mimic\n",
    "print(\"\\n2. MIMIC (AI copies performer)\")\n",
    "print(\"   AI follows your every move\")\n",
    "audio2 = generate_duet_with_strategy('mimic')\n",
    "display(Audio(audio2, rate=44100))\n",
    "\n",
    "# Strategy 3: Independent\n",
    "print(\"\\n3. INDEPENDENT (AI ignores performer)\")\n",
    "print(\"   AI does its own thing\")\n",
    "audio3 = generate_duet_with_strategy('independent')\n",
    "display(Audio(audio3, rate=44100))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Which strategy sounds most musical?\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nCall-and-response typically creates the most engaging dialogue.\")\n",
    "print(\"The AI responds to you but maintains its own voice.\")\n",
    "print(\"\\n✓ This is the goal: Musical interaction, not imitation or autonomy.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. ✓ **AI as co-performer** — Responsive musical partner, not autonomous\n",
    "2. ✓ **Call-and-response** — AI fills space when performer is sparse\n",
    "3. ✓ **Harmonic support** — AI follows performer's musical character\n",
    "4. ✓ **Musical dialogue** — Interaction analysis shows complementary behavior\n",
    "5. ✓ **Strategy comparison** — Call-and-response vs mimic vs independent\n",
    "\n",
    "### Key Insights\n",
    "\n",
    "- **AI is not autonomous** — It responds to your input\n",
    "- **You lead, AI follows** — But with its own voice\n",
    "- **Musical interaction** — Not random accompaniment\n",
    "- **Performer agency** — You control the relationship\n",
    "\n",
    "### Design Principles for AI Co-Performers\n",
    "\n",
    "1. **Responsiveness** — AI reacts to performer in musically meaningful ways\n",
    "2. **Complementarity** — AI adds to, doesn't duplicate, performer\n",
    "3. **Transparency** — Relationship is understandable and predictable\n",
    "4. **Controllability** — Performer can adjust AI behavior\n",
    "5. **Musical coherence** — AI behavior is musically motivated\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- **Customize AI strategy** — Adjust response patterns to your preference\n",
    "- **Add temporal memory** — AI remembers longer-term patterns\n",
    "- **Multiple AI voices** — Create ensemble performances\n",
    "- **Real-time parameter control** — Adjust AI responsiveness during performance\n",
    "- **Perform live** — Try it with an audience!\n",
    "\n",
    "---\n",
    "\n",
    "**Remember**: The goal is **meaningful human–AI collaboration**,  \n",
    "not replacing human creativity with autonomous AI."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
