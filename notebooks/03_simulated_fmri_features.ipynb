{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulated fMRI Feature Extraction\n",
    "\n",
    "This notebook demonstrates simulating and extracting features from fMRI (functional Magnetic Resonance Imaging) data for brain-music research.\n",
    "\n",
    "## Background\n",
    "- **fMRI** measures blood oxygen level-dependent (BOLD) signals\n",
    "- **Spatial resolution**: ~2-3mm (excellent)\n",
    "- **Temporal resolution**: ~1-2s (limited by hemodynamic response)\n",
    "- **Coverage**: Whole brain\n",
    "\n",
    "## Use Cases\n",
    "- Localizing creativity-related brain regions\n",
    "- Identifying music-responsive networks\n",
    "- Studying functional connectivity patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal, stats\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Simulate fMRI Time Series\n",
    "\n",
    "We'll simulate BOLD responses for different brain regions during a music listening task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "TR = 2.0  # Repetition time in seconds (typical fMRI)\n",
    "duration = 300  # 5 minutes scan\n",
    "n_timepoints = int(duration / TR)\n",
    "time = np.arange(n_timepoints) * TR\n",
    "\n",
    "# Define regions of interest (ROIs)\n",
    "roi_names = [\n",
    "    'Auditory Cortex',\n",
    "    'Default Mode Network',\n",
    "    'Executive Control Network',\n",
    "    'Reward System'\n",
    "]\n",
    "\n",
    "print(f\"Simulating fMRI scan: {n_timepoints} timepoints, TR={TR}s\")\n",
    "print(f\"ROIs: {', '.join(roi_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hrf(times, delay=6, undershoot_delay=16):\n",
    "    \"\"\"Create canonical hemodynamic response function\"\"\"\n",
    "    hrf = np.zeros_like(times)\n",
    "    hrf = (times ** (delay - 1) * np.exp(-times) / np.math.factorial(delay - 1) -\n",
    "           0.35 * times ** (undershoot_delay - 1) * np.exp(-times) / \n",
    "           np.math.factorial(undershoot_delay - 1))\n",
    "    hrf[times < 0] = 0\n",
    "    return hrf / hrf.max()\n",
    "\n",
    "# Create HRF for convolution\n",
    "hrf_time = np.arange(0, 30, TR)\n",
    "hrf = create_hrf(hrf_time)\n",
    "\n",
    "# Plot HRF\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(hrf_time, hrf, linewidth=2)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Response')\n",
    "plt.title('Canonical Hemodynamic Response Function (HRF)')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate neural activity for different conditions\n",
    "# Condition: music listening with creative engagement\n",
    "\n",
    "# Auditory cortex: sustained activation during music\n",
    "auditory_neural = np.ones(n_timepoints) + 0.3 * np.random.randn(n_timepoints)\n",
    "\n",
    "# Default mode network: increases during creative/imaginative moments\n",
    "creative_moments = np.random.choice([0, 1], size=n_timepoints, p=[0.7, 0.3])\n",
    "dmn_neural = creative_moments + 0.2 * np.random.randn(n_timepoints)\n",
    "\n",
    "# Executive control: periodic engagement for analytical listening\n",
    "executive_neural = 0.5 * np.sin(2 * np.pi * time / 60) + 0.3 * np.random.randn(n_timepoints)\n",
    "executive_neural[executive_neural < 0] = 0\n",
    "\n",
    "# Reward system: spikes during particularly enjoyable moments\n",
    "reward_spikes = np.zeros(n_timepoints)\n",
    "spike_times = np.random.choice(n_timepoints, size=10, replace=False)\n",
    "reward_spikes[spike_times] = np.random.uniform(1, 2, size=10)\n",
    "reward_neural = reward_spikes + 0.2 * np.random.randn(n_timepoints)\n",
    "\n",
    "# Convolve with HRF to get BOLD signals\n",
    "bold_signals = np.zeros((len(roi_names), n_timepoints))\n",
    "neural_signals = [auditory_neural, dmn_neural, executive_neural, reward_neural]\n",
    "\n",
    "for i, neural in enumerate(neural_signals):\n",
    "    bold = np.convolve(neural, hrf, mode='same')\n",
    "    # Add scanner noise and drift\n",
    "    drift = np.linspace(0, 0.5, n_timepoints)\n",
    "    noise = 0.1 * np.random.randn(n_timepoints)\n",
    "    bold_signals[i] = bold + drift + noise\n",
    "\n",
    "print(\"âœ“ fMRI BOLD signals simulated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize simulated fMRI signals\n",
    "fig, axes = plt.subplots(4, 1, figsize=(14, 10))\n",
    "\n",
    "for i, (ax, name) in enumerate(zip(axes, roi_names)):\n",
    "    ax.plot(time, bold_signals[i], linewidth=1.5)\n",
    "    ax.set_ylabel('BOLD Signal')\n",
    "    ax.set_title(f'{name}')\n",
    "    ax.grid(alpha=0.3)\n",
    "    \n",
    "axes[-1].set_xlabel('Time (s)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Extraction\n",
    "\n",
    "Extract meaningful features from fMRI data for brain-music mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fmri_features(bold_signals, roi_names, window_size=10):\n",
    "    \"\"\"Extract features from fMRI BOLD signals\"\"\"\n",
    "    features = {}\n",
    "    n_rois, n_timepoints = bold_signals.shape\n",
    "    \n",
    "    # 1. Mean activation per ROI\n",
    "    features['mean_activation'] = np.mean(bold_signals, axis=1)\n",
    "    \n",
    "    # 2. Temporal variance (variability)\n",
    "    features['temporal_variance'] = np.var(bold_signals, axis=1)\n",
    "    \n",
    "    # 3. Peak activation\n",
    "    features['peak_activation'] = np.max(bold_signals, axis=1)\n",
    "    \n",
    "    # 4. Functional connectivity (correlation between ROIs)\n",
    "    features['connectivity_matrix'] = np.corrcoef(bold_signals)\n",
    "    \n",
    "    # 5. Windowed features (for time-varying analysis)\n",
    "    n_windows = n_timepoints // window_size\n",
    "    windowed_mean = np.zeros((n_rois, n_windows))\n",
    "    \n",
    "    for i in range(n_windows):\n",
    "        start = i * window_size\n",
    "        end = (i + 1) * window_size\n",
    "        windowed_mean[:, i] = np.mean(bold_signals[:, start:end], axis=1)\n",
    "    \n",
    "    features['windowed_activation'] = windowed_mean\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Extract features\n",
    "features = extract_fmri_features(bold_signals, roi_names)\n",
    "\n",
    "print(\"Extracted features:\")\n",
    "for key, value in features.items():\n",
    "    if isinstance(value, np.ndarray):\n",
    "        print(f\"  {key}: shape {value.shape}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Mean activation\n",
    "axes[0, 0].bar(roi_names, features['mean_activation'])\n",
    "axes[0, 0].set_ylabel('Mean BOLD Signal')\n",
    "axes[0, 0].set_title('Mean Activation per ROI')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Temporal variance\n",
    "axes[0, 1].bar(roi_names, features['temporal_variance'])\n",
    "axes[0, 1].set_ylabel('Variance')\n",
    "axes[0, 1].set_title('Temporal Variability')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Functional connectivity\n",
    "im = axes[1, 0].imshow(features['connectivity_matrix'], cmap='coolwarm', vmin=-1, vmax=1)\n",
    "axes[1, 0].set_xticks(range(len(roi_names)))\n",
    "axes[1, 0].set_yticks(range(len(roi_names)))\n",
    "axes[1, 0].set_xticklabels(roi_names, rotation=45, ha='right')\n",
    "axes[1, 0].set_yticklabels(roi_names)\n",
    "axes[1, 0].set_title('Functional Connectivity Matrix')\n",
    "plt.colorbar(im, ax=axes[1, 0])\n",
    "\n",
    "# Windowed activation (first ROI)\n",
    "axes[1, 1].plot(features['windowed_activation'][0], marker='o')\n",
    "axes[1, 1].set_xlabel('Time Window')\n",
    "axes[1, 1].set_ylabel('Mean Activation')\n",
    "axes[1, 1].set_title(f'Windowed Activation: {roi_names[0]}')\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dimensionality Reduction for Latent Mapping\n",
    "\n",
    "Reduce high-dimensional fMRI features for mapping to music latent spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Prepare feature matrix (combine all features)\n",
    "# For this example, use windowed activation across all ROIs\n",
    "feature_matrix = features['windowed_activation'].T  # Shape: (n_windows, n_rois)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(feature_matrix)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=2)\n",
    "features_pca = pca.fit_transform(features_scaled)\n",
    "\n",
    "print(f\"Original feature shape: {feature_matrix.shape}\")\n",
    "print(f\"Reduced feature shape: {features_pca.shape}\")\n",
    "print(f\"Explained variance ratio: {pca.explained_variance_ratio_}\")\n",
    "print(f\"Total variance explained: {pca.explained_variance_ratio_.sum():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize PCA projection\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter = plt.scatter(features_pca[:, 0], features_pca[:, 1], \n",
    "                     c=np.arange(len(features_pca)), cmap='viridis', s=100)\n",
    "plt.colorbar(scatter, label='Time Window')\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)')\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)')\n",
    "plt.title('fMRI Features in PCA Space (Trajectory Over Time)')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What We Did\n",
    "1. Simulated realistic fMRI BOLD signals for music-related brain regions\n",
    "2. Extracted multiple feature types:\n",
    "   - Mean activation levels\n",
    "   - Temporal variability\n",
    "   - Functional connectivity\n",
    "   - Time-windowed activation patterns\n",
    "3. Reduced dimensionality for latent space mapping\n",
    "\n",
    "### Key Insights\n",
    "- fMRI provides **spatial specificity** - which regions are active\n",
    "- **Connectivity patterns** reveal network-level dynamics\n",
    "- **Temporal dynamics** are limited (slow hemodynamic response)\n",
    "- PCA reveals **low-dimensional structure** in brain activity\n",
    "\n",
    "### Next Steps\n",
    "1. Map these features to music model latent spaces (see `06_latent_space_mapping.ipynb`)\n",
    "2. Compare with EEG features for complementary information\n",
    "3. Explore more sophisticated feature extraction (GLM, connectivity metrics)\n",
    "\n",
    "### Limitations\n",
    "- Simulated data lacks real brain complexity\n",
    "- Real fMRI requires artifact removal, motion correction, preprocessing\n",
    "- Individual differences not captured here\n",
    "- Real-time fMRI challenging due to processing requirements"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
